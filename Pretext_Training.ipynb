{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b67a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as Image\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from skimage.io import imread, imshow\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4c8127",
   "metadata": {},
   "source": [
    "\n",
    "### Loading images dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12f9c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the path of the pseudo labelled images, and using them as a pretext training task\n",
    "trainpath= ('E/Dataset/data-augmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291bbe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height=224\n",
    "img_width=224\n",
    "batch_size=128\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "    validation_split=0.2) # set validation split\n",
    "\n",
    "print(\"The data is being split into training and validation set\")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory( trainpath,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training') # set as training data\n",
    "print(\"----------------------------------------------------------------\")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(trainpath,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation') # set as validation data\n",
    "\n",
    "#define labels for training\n",
    "class_names = train_generator.class_indices\n",
    "print('Number of Pseudo-Labels after applying DSCAN algorithm: ',class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8efa641",
   "metadata": {},
   "source": [
    "### Building the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5b3635",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the pretrained model without the output of the last convolution block \n",
    "\n",
    "base_model = ResNet50(include_top=False, input_shape=(224, 224, 3), weights = 'imagenet')\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = Flatten()(base_model.output)\n",
    "\n",
    "# Add a fully connected layer with 2048 hidden units and ReLU activation\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# Adapt the final classification layer of an ImageNet pre-trained cNN model to the decomposed classes.\n",
    "predictions = Dense(len(class_decomposition), activation='softmax')(x)\n",
    "\n",
    "base_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "base_model.summary()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921ea979",
   "metadata": {},
   "source": [
    "### Training the model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5c5556",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#define checkpoint\n",
    "checkpoint = ModelCheckpoint(filepath='pretext_braintumour.hdf5', \n",
    "                             monitor='val_accuracy',\n",
    "                             save_best_only=True, \n",
    "                             mode='auto',\n",
    "                             verbose=1)   \n",
    "\n",
    "#early stopping\n",
    "earlystop=EarlyStopping( monitor=\"val_accuracy\", \n",
    "                        patience=10,  \n",
    "                        mode=\"auto\")\n",
    "\n",
    "model_callbacks = [checkpoint, earlystop]\n",
    "\n",
    "\n",
    "optimize = SGD(learning_rate=0.0001, decay=0.9 / 10, momentum=0.9, nesterov=True)\n",
    "DeTraC_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "#compile model\n",
    "DeTraC_model.compile(loss='mse', optimizer=optimize, metrics=['accuracy']) \n",
    "    \n",
    "# train the model\n",
    "history=DeTraC_model.fit(train_generator, \n",
    "                               steps_per_epoch=train_generator.n//train_generator.batch_size,\n",
    "                               validation_data= validation_generator,\n",
    "                               validation_steps=validation_generator.n//validation_generator.batch_size,\n",
    "                               epochs=50, \n",
    "                               callbacks= model_callbacks, \n",
    "                               verbose=1, shuffle= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd4d5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing results and model accuracy \n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a95b1f",
   "metadata": {},
   "source": [
    "### Evaluate the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8c5537",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_Loss, val_Acc = pretext_model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f11cb00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
